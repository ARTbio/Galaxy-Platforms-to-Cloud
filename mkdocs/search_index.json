{
    "docs": [
        {
            "location": "/", 
            "text": "PtC\n\n\nDevelopments for deploying Galaxy servers with slurm clusters in local or cloud infrastructures", 
            "title": "Home"
        }, 
        {
            "location": "/#ptc", 
            "text": "Developments for deploying Galaxy servers with slurm clusters in local or cloud infrastructures", 
            "title": "PtC"
        }, 
        {
            "location": "/setup_nfs/", 
            "text": "Set Up a simple NFS for the virtual cluster\n\n\nOn slurmd \n slurmctld control node side (ie GalaxyKickStart instance)\n\n\n\n\nEdit* and Run as root the script \nset_nfs_on_master_node.sh\n that will\n\n\ninstall and run \nnfs-kernel-server\n and \nnfs-common\n packages.\n\n\ncreate \n/nfs_export\n and \n/nfs_export/galaxy\n directories (for bind mounts of /home/galaxy and other file system bind mounted within /home/galaxy)\n\n\nchange the \n/etc/fstab\n file for making permanent the bind mounts\n\n\nmodify the \n/etc/exports\n file for appropriate sharing\n\n\nrestart NFS server ( \nsudo /etc/init.d/nfs-kernel-server restart\n)\n\n\n*Be aware that the current scenario is played after GKS galaxy install and export of permanent Galaxy data on an extra mounted volume (see the \n$GKS_EXPORT_DIR\n variable in the script). The \n$IP_RANGE\n should also been edited before running the script, according to your slurm network\n\n\nBe aware that GKS modified the \n/etc/fstab\n file prior this script is permanent data was chosen to be exported on permanent or snapshotable volume. \n\n\n\n\n\n\n\n\nOn slurmd slave nodes sides\n\n\n\n\n\n\nEdit and run as root the script \n that will:\n\n\n\n\n\n\napt-get install nfs-common\n\n\n\n\ncreate the galaxy 1450:100 user, as well as the mounting point for shared nfs volume (\n/home/galaxy\n). \nStill to be scripted.\n\n\nmount the shared /home/galaxy volume as well as its bind mounted sub file systems. see the \nslurm_node_up.sh\n script.", 
            "title": "Set up NFS"
        }, 
        {
            "location": "/setup_nfs/#set-up-a-simple-nfs-for-the-virtual-cluster", 
            "text": "", 
            "title": "Set Up a simple NFS for the virtual cluster"
        }, 
        {
            "location": "/setup_nfs/#on-slurmd-slurmctld-control-node-side-ie-galaxykickstart-instance", 
            "text": "Edit* and Run as root the script  set_nfs_on_master_node.sh  that will  install and run  nfs-kernel-server  and  nfs-common  packages.  create  /nfs_export  and  /nfs_export/galaxy  directories (for bind mounts of /home/galaxy and other file system bind mounted within /home/galaxy)  change the  /etc/fstab  file for making permanent the bind mounts  modify the  /etc/exports  file for appropriate sharing  restart NFS server (  sudo /etc/init.d/nfs-kernel-server restart )  *Be aware that the current scenario is played after GKS galaxy install and export of permanent Galaxy data on an extra mounted volume (see the  $GKS_EXPORT_DIR  variable in the script). The  $IP_RANGE  should also been edited before running the script, according to your slurm network  Be aware that GKS modified the  /etc/fstab  file prior this script is permanent data was chosen to be exported on permanent or snapshotable volume.", 
            "title": "On slurmd &amp; slurmctld control node side (ie GalaxyKickStart instance)"
        }, 
        {
            "location": "/setup_nfs/#on-slurmd-slave-nodes-sides", 
            "text": "Edit and run as root the script   that will:    apt-get install nfs-common   create the galaxy 1450:100 user, as well as the mounting point for shared nfs volume ( /home/galaxy ).  Still to be scripted.  mount the shared /home/galaxy volume as well as its bind mounted sub file systems. see the  slurm_node_up.sh  script.", 
            "title": "On slurmd slave nodes sides"
        }, 
        {
            "location": "/get_mississippi_tool_list/", 
            "text": "Procedure to get tool list from a Galaxy instance\n\n\n\n\nInstall pip (version pip 9.0.1)\n\n\nInstall virtualenv \npip install virtualenv\n\n\nvirtualenv .venv\n\n\nsource .venv/bin/activate\n\n\npip install requests\n\n\npip install PyYAML\n\n\npip install virtualenv\n\n\ngit clone https://github.com/galaxyproject/ephemeris.git\n\n\ncd ephemeris\n\n\npython get_tool_list_from_galaxy.py --help\n\n\npython get_tool_list_from_galaxy.py -g https://mississippi.snv.jussieu.fr/ -o mississippi_tool_list.yml\n\n\npython get_tool_list_from_galaxy.py --include_tool_panel_id -g https://mississippi.snv.jussieu.fr/ -o mississippi_tool_list_panelIDs.yml\n\n\n\n\nThe two files generated are in tool_lists\n\n\nThen\n\n\nGrep \n(^  tool_shed_url.+)\\r\n replace \n\\1\\r  install_resolver_dependencies: True\\r\n\n\nto generate the file \nmississippi_tool_list_with_ install_resolver_dependencies.yml\n\n\nWe have also to include the datamanagers tools in the list !\n\n\nFor instance, in https://mississippi.snv.jussieu.fr, we have:\n\n\n\n\nBWA index - builder\n\n\nBWA-MEM index - builder\n\n\nBowtie index - builder\n\n\nBowtie2 index - builder\n\n\nCreate DBKey and Reference Genome - fetching\n\n\nHISAT2 index - builder\n\n\nSAM FASTA index - builder\n\n\nTwoBit - builder\n\n\nrnastar index - builder\n\n\n\n\nand for instance, a typical entry for a data_manager tool in the yml list is:\n\n\n- name: data_manager_bowtie2_index_builder\n  owner: devteam\n  revisions:\n  - e87aeff2cf88\n  tool_panel_section_label: null\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n  install_resolver_dependencies: True\n\n\n\n\nand we can probably ignore the revisions key to get the latest revision", 
            "title": "Get Galaxy tool lists"
        }, 
        {
            "location": "/get_mississippi_tool_list/#procedure-to-get-tool-list-from-a-galaxy-instance", 
            "text": "Install pip (version pip 9.0.1)  Install virtualenv  pip install virtualenv  virtualenv .venv  source .venv/bin/activate  pip install requests  pip install PyYAML  pip install virtualenv  git clone https://github.com/galaxyproject/ephemeris.git  cd ephemeris  python get_tool_list_from_galaxy.py --help  python get_tool_list_from_galaxy.py -g https://mississippi.snv.jussieu.fr/ -o mississippi_tool_list.yml  python get_tool_list_from_galaxy.py --include_tool_panel_id -g https://mississippi.snv.jussieu.fr/ -o mississippi_tool_list_panelIDs.yml   The two files generated are in tool_lists  Then  Grep  (^  tool_shed_url.+)\\r  replace  \\1\\r  install_resolver_dependencies: True\\r  to generate the file  mississippi_tool_list_with_ install_resolver_dependencies.yml", 
            "title": "Procedure to get tool list from a Galaxy instance"
        }, 
        {
            "location": "/get_mississippi_tool_list/#we-have-also-to-include-the-datamanagers-tools-in-the-list", 
            "text": "For instance, in https://mississippi.snv.jussieu.fr, we have:   BWA index - builder  BWA-MEM index - builder  Bowtie index - builder  Bowtie2 index - builder  Create DBKey and Reference Genome - fetching  HISAT2 index - builder  SAM FASTA index - builder  TwoBit - builder  rnastar index - builder   and for instance, a typical entry for a data_manager tool in the yml list is:  - name: data_manager_bowtie2_index_builder\n  owner: devteam\n  revisions:\n  - e87aeff2cf88\n  tool_panel_section_label: null\n  tool_shed_url: https://toolshed.g2.bx.psu.edu/\n  install_resolver_dependencies: True  and we can probably ignore the revisions key to get the latest revision", 
            "title": "We have also to include the datamanagers tools in the list !"
        }
    ]
}